#!/usr/bin/env python3
"""
Test script to validate key methods and functions in the weather forecasting solution
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import sys

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import tempfile

def test_data_loading():
    """Test data loading functionality"""
    print("üß™ Testing data loading functionality...")

    # Create sample data
    timestamps = pd.date_range('2023-01-01', periods=100, freq='H')
    sample_data = pd.DataFrame({
        'timestamp': timestamps,
        'temperature': np.random.normal(20, 5, 100),
        'humidity': np.random.uniform(30, 80, 100),
        'wind_speed': np.random.exponential(5, 100),
        'precipitation': np.random.exponential(1, 100)
    })

    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
        test_file = f.name
        sample_data.to_csv(test_file, index=False)

    try:
        # Test loading
        loaded_df = pd.read_csv(test_file, parse_dates=['timestamp'])
        loaded_df['timestamp'] = pd.to_datetime(loaded_df['timestamp'])
        loaded_df = loaded_df.set_index('timestamp')

        assert len(loaded_df) == 100, f"Expected 100 rows, got {len(loaded_df)}"
        assert 'temperature' in loaded_df.columns, "Temperature column missing"
        assert loaded_df.index.is_monotonic_increasing, "Index should be sorted"

        print("‚úÖ Data loading test passed")
        return True

    except Exception as e:
        print(f"‚ùå Data loading test failed: {e}")
        return False
    finally:
        if os.path.exists(test_file):
            os.remove(test_file)

def test_feature_engineering():
    """Test feature engineering functionality"""
    print("üß™ Testing feature engineering functionality...")

    try:
        # Create sample data
        timestamps = pd.date_range('2023-01-01', periods=168, freq='H')  # 1 week
        df = pd.DataFrame({
            'timestamp': timestamps,
            'temperature': 20 + 10 * np.sin(2 * np.pi * np.arange(168) / 24) + np.random.normal(0, 2, 168),
            'humidity': np.random.uniform(40, 70, 168),
            'wind_speed': np.random.exponential(5, 168),
            'precipitation': np.random.exponential(0.5, 168)
        })
        df = df.set_index('timestamp')

        # Test temporal features
        df['hour'] = df.index.hour
        df['day_of_week'] = df.index.dayofweek
        df['month'] = df.index.month

        # Test cyclical encoding
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)

        # Test weather features
        if 'temperature' in df.columns:
            df['temp_rolling_mean_24h'] = df['temperature'].rolling(window=24, min_periods=1).mean()
            df['temp_change_1h'] = df['temperature'].diff()

        # Test lag features
        df['temperature_lag_1'] = df['temperature'].shift(1)
        df['temperature_lag_24'] = df['temperature'].shift(24)

        # Test missing data handling
        df_with_nan = df.copy()
        df_with_nan.loc[df_with_nan.sample(frac=0.1).index, 'temperature'] = np.nan
        df_filled = df_with_nan.interpolate(method='linear')

        # Assertions
        assert 'hour_sin' in df.columns, "Cyclical encoding failed"
        assert 'temp_rolling_mean_24h' in df.columns, "Rolling features failed"
        assert 'temperature_lag_1' in df.columns, "Lag features failed"
        assert df_filled['temperature'].isnull().sum() == 0, "Missing data handling failed"

        print("‚úÖ Feature engineering test passed")
        return True

    except Exception as e:
        print(f"‚ùå Feature engineering test failed: {e}")
        return False

def test_data_validation():
    """Test data validation and quality checks"""
    print("üß™ Testing data validation functionality...")

    try:
        # Create sample data with issues
        timestamps = pd.date_range('2023-01-01', periods=100, freq='H')
        df = pd.DataFrame({
            'timestamp': timestamps,
            'temperature': [20] * 50 + [np.nan] * 50,  # Half missing
            'humidity': np.random.uniform(30, 80, 100),
        })
        df = df.set_index('timestamp')

        # Test missing data percentage
        missing_pct = df.isnull().mean().mean()
        assert missing_pct > 0, "Should have missing data"

        # Test data quality checks
        if df.empty:
            raise ValueError("Data should not be empty")

        # Test anomaly detection (IQR method)
        temp_data = df['temperature'].dropna()
        if len(temp_data) > 10:
            Q1 = temp_data.quantile(0.25)
            Q3 = temp_data.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            anomalies = ((temp_data < lower_bound) | (temp_data > upper_bound)).sum()
            assert isinstance(anomalies, (int, np.integer)), "Anomaly count should be integer"

        print("‚úÖ Data validation test passed")
        return True

    except Exception as e:
        print(f"‚ùå Data validation test failed: {e}")
        return False

def test_file_path_detection():
    """Test the data path detection logic"""
    print("üß™ Testing file path detection logic...")

    try:
        # Create test files
        test_dir = '/tmp/test_data'
        os.makedirs(test_dir, exist_ok=True)

        test_files = [
            'weather_data.csv',
            'new_york_weather_data.csv',
            'london_weather_data.csv'
        ]

        # Create empty test files
        for filename in test_files:
            filepath = os.path.join(test_dir, filename)
            pd.DataFrame({'timestamp': ['2023-01-01'], 'temperature': [20]}).to_csv(filepath, index=False)

        # Test path detection logic
        possible_paths = [
            os.path.join(test_dir, 'weather_data.csv'),
            os.path.join(test_dir, 'new_york_weather_data.csv'),
            os.path.join(test_dir, 'london_weather_data.csv'),
            os.path.join(test_dir, 'paris_weather_data.csv'),  # Doesn't exist
        ]

        found_path = None
        location = "Unknown City"

        for path in possible_paths:
            if os.path.exists(path):
                try:
                    df_check = pd.read_csv(path, nrows=5)
                    if len(df_check) > 0:
                        found_path = path
                        filename = os.path.basename(path)
                        if 'weather_data.csv' in filename:
                            location_part = filename.replace('_weather_data.csv', '').replace('weather_data.csv', 'data')
                            location = location_part.title() if location_part != 'weather' else 'Loaded City'
                        break
                except Exception:
                    continue

        assert found_path is not None, "Should find at least one test file"
        assert location != "Unknown City", "Should extract location from filename"

        print("‚úÖ File path detection test passed")
        return True

    except Exception as e:
        print(f"‚ùå File path detection test failed: {e}")
        return False
    finally:
        # Cleanup
        import shutil
        if os.path.exists(test_dir):
            shutil.rmtree(test_dir)

def test_save_data_method():
    """Test the save_data method structure and error handling"""
    print("üß™ Testing save_data method structure...")

    try:
        # Create sample processed data
        timestamps = pd.date_range('2023-01-01', periods=50, freq='H')
        processed_df = pd.DataFrame({
            'timestamp': timestamps,
            'temperature': np.random.normal(20, 5, 50),
            'humidity': np.random.uniform(30, 80, 50),
            'temp_rolling_mean_24h': np.random.normal(20, 2, 50),
            'hour': timestamps.hour,
            'day_of_week': timestamps.dayofweek,
            'temperature_lag_1': np.random.normal(20, 5, 50)
        })

        # Test method signature validation
        def validate_save_data_signature(df, storage_type='iceberg', table_name='test_table', **kwargs):
            """Mock validation of save_data method logic"""
            if not isinstance(df, pd.DataFrame):
                raise ValueError("df must be a pandas DataFrame")

            if storage_type not in ['iceberg', 'postgres']:
                raise ValueError("Unsupported storage type")

            if not table_name:
                raise ValueError("table_name cannot be empty")

            # Simulate Spark DataFrame creation
            try:
                # This would normally be: spark_df = self.spark.createDataFrame(df.reset_index())
                spark_df_mock = df.reset_index()  # Mock conversion
                assert len(spark_df_mock) == len(df), "DataFrame conversion failed"
            except Exception as e:
                raise RuntimeError(f"Spark DataFrame creation failed: {e}")

            # Test storage logic
            if storage_type == 'iceberg':
                table_name_full = f"iceberg.{table_name}"
                # In real implementation: spark_df.writeTo(table_name_full).using("iceberg").createOrReplace()
                assert table_name_full == f"iceberg.{table_name}", "Iceberg table naming failed"

            elif storage_type == 'postgres':
                postgres_url = kwargs.get('postgres_url', 'jdbc:postgresql://localhost:5432/weather_db')
                user = kwargs.get('user', 'postgres')
                password = kwargs.get('password', 'password')

                assert postgres_url.startswith('jdbc:postgresql://'), "Invalid PostgreSQL URL"
                assert user and password, "Missing database credentials"

            return True

        # Test valid calls
        assert validate_save_data_signature(processed_df, 'iceberg', 'weather_data')
        assert validate_save_data_signature(processed_df, 'postgres', 'weather_data',
                                         postgres_url='jdbc:postgresql://test:5432/db',
                                         user='testuser', password='testpass')

        # Test invalid calls
        try:
            validate_save_data_signature("not a dataframe", 'iceberg', 'test')
            assert False, "Should have raised ValueError for invalid df"
        except ValueError:
            pass

        try:
            validate_save_data_signature(processed_df, 'invalid_type', 'test')
            assert False, "Should have raised ValueError for invalid storage type"
        except ValueError:
            pass

        try:
            validate_save_data_signature(processed_df, 'iceberg', '')
            assert False, "Should have raised ValueError for empty table name"
        except ValueError:
            pass

        print("‚úÖ Save data method structure test passed")
        return True

    except Exception as e:
        print(f"‚ùå Save data method test failed: {e}")
        return False

def run_all_tests():
    """Run all validation tests"""
    print("üöÄ Starting validation tests for weather forecasting solution\n")

    tests = [
        test_data_loading,
        test_feature_engineering,
        test_data_validation,
        test_file_path_detection,
        test_save_data_method,
    ]

    passed = 0
    total = len(tests)

    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"‚ùå Test {test.__name__} crashed: {e}")

    print(f"\nüìä Test Results: {passed}/{total} tests passed")

    if passed == total:
        print("üéâ All tests passed! The methods and functions are working correctly.")
        return True
    else:
        print("‚ö†Ô∏è  Some tests failed. Please review the implementation.")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)